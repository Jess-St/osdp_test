name: run Data_Pipeline.py

on:
  schedule:
    - cron: '*/5 * * * *' # every 30 mins (https://crontab.guru/every-30-minutes)

jobs:
  build:
    runs-on: ubuntu-latest

    permissions:
      # Give the default GITHUB_TOKEN write permission to commit and push the
      # added or changed files to the repository.
      contents: write

    steps:

      - name: checkout repo content
        uses: actions/checkout@v3 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10' # install the python version needed
          
      - name: install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: execute py script # run Data_Pipeline.py
        env:
          BMRS_API_KEY: ${{ secrets.BMRS_API_KEY }}
          OSDP: ${{ github.workspace }}
        run: python ${{ github.workspace }}/notebooks/py_versions/Data_Pipeline.py

      - name: Saving changes to repo
        uses: stefanzweifel/git-auto-commit-action@v4 

      # - name: commit files
      #   run: |
      #     git config --local user.email "action@github.com"
      #     git config --local user.name "GitHub Action"
      #     git add -A
      #     git diff-index --quiet HEAD || (git commit -a -m "Updated datasets" --allow-empty)
          
      # - name: push changes
      #   uses: ad-m/github-push-action@master
      #   with:
      #     github_token: ${{ secrets.GITHUB_TOKEN }}
      #     branch: main 
